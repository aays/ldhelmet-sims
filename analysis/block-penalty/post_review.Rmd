---
title: "Block penalty simulations analysis - post review"
author: Ahmed Hasan
output: pdf_notebook
---

Similar to `analysis.Rmd`, but for varying hotspot lengths

```{r}
library(tidyverse)
library(fs)
library(magrittr, warn.conflicts = FALSE)
library(glue)
library(here)

# for exporting plots
din1 <- 6.34375
din2 <- 3.385417
```

# Loading in data

```{r}
load_ldhelmet_files <- function(window, flank, block, hot_length) {
  # window and flank in kb
  
  full_dir <- glue('data/macs-runs-hotspot-length/hot_{hot_length}k/ldhelmet_{window}_{flank}/block_{block}')
  
  out <- dir_ls(here(full_dir)) %>% 
    map_dfr(., read_csv, col_types = cols(), .id = 'name') %>% 
    select(-chr) %>%
    mutate(name = str_extract(name, '[0-9]\\.[0-9]+_10[0-9]')) %>% # get fname
    separate(name, into = c('rho', 'run'), sep = '_', convert = TRUE) %>%  # pull rho + run out of fname
    rename(start = block_start, end = block_end)
  return(out)
}

block_5_4k <- load_ldhelmet_files(2000, 40000, 5, 4)
block_10_4k <- load_ldhelmet_files(2000, 40000, 10, 4)
block_50_4k <- load_ldhelmet_files(2000, 40000, 50, 4)
block_100_4k <- load_ldhelmet_files(2000, 40000, 100, 4)
block_5_6k <- load_ldhelmet_files(2000, 40000, 5, 6)
block_10_6k <- load_ldhelmet_files(2000, 40000, 10, 6)
block_50_6k <- load_ldhelmet_files(2000, 40000, 50, 6)
block_100_6k <- load_ldhelmet_files(2000, 40000, 100, 6)

block_5_4k
```

# Exploring the data

## Overall distributions

What does the distribution of rho look like in block = 10?

```{r}
ggplot(block_10, aes(x = block_rate)) +
  geom_histogram() +
  theme_classic()
```

For 4k - Hotspots were supposed to be placed as follows:

```
0.0500	0.0540	10.00000
0.1786	0.1826	10.00000
0.3071	0.3111	20.00000
0.4357	0.4397	20.00000
0.5643	0.5683	40.00000
0.6929	0.6969	40.00000
0.8214	0.8254	60.00000
0.9500	0.9540	60.00000
```

Where the first two columns represent chunks of the sequence (over [0, 1])
and the third one represents fold increase over baseline rho (i.e. value in filename)

For 2 kb joins - need to split 4 kb hotspot row into two 2 kb rows, 3 in the
case of 6 kb, etc

```{r}
hotspots <- data.frame(
  prop_start = c(0.0500, 0.1786, 0.3071, 0.4357, 0.5643, 0.6929, 0.8214, 0.9500),
  prop_end = c(0.0520, 0.1806, 0.3091, 0.4377, 0.5663, 0.6949, 0.8234, 0.9520),
  rate_increase = c(10, 10, 20, 20, 40, 40, 60, 60)
) %>%
  mutate(exact_start = prop_start * 1e6,
         exact_end = prop_end * 1e6) %>% 
  select(-starts_with('prop')) %>% 
  mutate(start = round(exact_start / 1000) * 1000,
         end = round(exact_end / 1000) * 1000) %>% 
  select(start, end, everything())

# split hotspots into 2 kb windows
hotspots_4k <- hotspots %>% 
  mutate_at(vars(contains('start'), contains('end')), function(x) x + 2000) %>% 
  bind_rows(hotspots) %>% 
  arrange(start)
hotspots_6k <- hotspots %>% 
  mutate_at(vars(contains('start'), contains('end')), function(x) x + 4000) %>% 
  bind_rows(hotspots_4k) %>% 
  arrange(start)
  
```

## Background rho estimation

Which block penalty gives the most accurate background rho estimates? (not including hotspots)

```{r}
non_overlapping <- function(df, windowsize) {
  df %<>%
    mutate(div = floor(start / windowsize), div2 = lead(div)) %>%
    filter(div == div2) %>%
    select(-contains('div'))
  return(df)
}

# starting with block 5
# quick and dirty visualization
block_5_4k %>%
  anti_join(hotspots, by = c('start', 'end')) %>% 
  ggplot(aes(x = block_rate)) +
  geom_histogram() +
  geom_vline(aes(xintercept = rho)) +
  facet_wrap(~ rho) +
  theme_classic()

block_5_4k %>% 
  anti_join(hotspots, by = c('start', 'end')) %>% 
  non_overlapping(2000) %>% 
  group_by(rho) %>% 
  summarise(estimate = mean(block_rate)) %>% 
  mutate(obs_exp = estimate / rho)
  
```

Expanding to all datasets:

```{r}
d_all_4k <- list(block_5_4k, block_10_4k, block_50_4k, block_100_4k)
d_all_6k <- list(block_5_6k, block_10_6k, block_50_6k, block_100_6k)
names(d_all_4k) <- c(5, 10, 50, 100)
names(d_all_6k) <- names(d_all_4k)

d_all_4k %>% 
  map(~ non_overlapping(., 2000)) %>% 
  map_dfr(~ anti_join(., hotspots_4k, by = c('start', 'end')) %>% 
            group_by(rho) %>% 
            summarise(estimate = mean(block_rate)) %>% 
            mutate(obs_exp = estimate / rho),
          .id = 'block') %>% 
  mutate(block = as.numeric(block),
         rho = forcats::fct_relevel(
           as.factor(rho), 
           levels = c('1e-04', '0.001', '0.01', '0.1', '1', '2.5'))
         ) %>% 
  ggplot(aes(x = rho, y = obs_exp, color = block)) +
  geom_point() +
  geom_line() + 
  geom_hline(yintercept = 1) +
  theme_classic()

d_all_6k %>% 
  map(~ non_overlapping(., 2000)) %>% 
  map_dfr(~ anti_join(., hotspots_4k, by = c('start', 'end')) %>% 
            group_by(rho) %>% 
            summarise(estimate = mean(block_rate)) %>% 
            mutate(obs_exp = estimate / rho),
          .id = 'block') %>% 
  mutate(block = as.numeric(block),
         rho = forcats::fct_relevel(
           as.factor(rho), 
           levels = c('1e-04', '0.001', '0.01', '0.1', '1', '2.5'))
         ) %>% 
  ggplot(aes(x = rho, y = obs_exp, color = block)) +
  geom_point() +
  geom_line() + 
  geom_hline(yintercept = 1) +
  theme_classic()
```

Looks like block = 100 is our best bet here in both cases, although this performs slightly worse
than the 2 kb hotspot dataset

### Fig. S1 - Obs/exp for different block penalties - will need to merge with other two and facet

```{r}
# make the scale discrete, not continuous

# combine datasets
summarise_obs_exp <- function(d, hotspot_size) {
  out <- d %>% 
    map(~ non_overlapping(., 2000)) %>% 
    map_dfr(~ anti_join(., hotspots_4k, by = c('start', 'end')) %>% 
              group_by(rho) %>% 
              summarise(estimate = mean(block_rate)) %>% 
              mutate(obs_exp = estimate / rho),
            .id = 'block') %>% 
    mutate(hotspot_size = hotspot_size)
  return(out)
}

# load d_all from other Rmd
fig_s1_data <- bind_rows(
  summarise_obs_exp(d_all, 2000),
  summarise_obs_exp(d_all_4k, 4000),
  summarise_obs_exp(d_all_6k, 6000)
)

fig_s1 <- fig_s1_data %>% 
  mutate(block = as.numeric(block),
         rho = forcats::fct_relevel(
           as.factor(rho), 
           levels = c('1e-04', '0.001', '0.01', '0.1', '1', '2.5')),
         block = forcats::fct_relevel(
           as.factor(block),
           levels = c('5', '10', '50', '100')
         )
         ) %>% 
  ggplot(aes(x = rho, y = obs_exp, color = block)) +
  facet_wrap(~ hotspot_size) +
  geom_point(size = 1.5) +
  geom_hline(yintercept = 1) +
  theme_classic() +
  coord_cartesian(
    y = c(0.5, 4.0)
  ) +
  labs(
    x = expression(paste('Simulated background ', rho)),
    y = expression(paste('Observed/Expected ', rho))
  ) +
  theme(
    axis.title = element_text(family = 'Helvetica', size = 8),
    axis.text = element_text(family = 'Helvetica', size = 8, colour = 'black'),
    legend.title = element_text(family = 'Helvetica', size = 12, colour = 'black'),
    legend.text = element_text(family = 'Helvetica', size = 10, colour = 'black'),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

fig_s1

ggsave(here('plots/fig_s1.pdf'), plot = fig_s1, width = din2 * 1.5, height = din2 * 0.75)
```



## Hotspot power estimation

power = 1 - prob of false negatives (known hotspots not detected as hotspots)

For each rho -> 10 runs, with 8 4 kb hotspots each -> max of 160 2 kb hotspot 'windows' per background rho per block

For each rho in 6 kb dataset -> 10 runs with 8 6 kb hotspots -> max of 10 * 8 * 3 -> 240 2 kb hotspot 'windows'/rho/block

40 hotspots per rate increase value per rho (group by rho, rate_increase and tally) for 4

60 hotspots per rate increase per rho for 6


```{r}
d_all_4k %>% 
  map_dfr(~ inner_join(., hotspots_4k, by = c('start', 'end')) %>% 
  filter(rate_ratio >= rate_increase) %>% 
  group_by(rho, rate_increase) %>% 
  tally() %>% 
  mutate(power = n / 40), # how many of the 40 windows were correctly called as hotspots
  .id = 'block') %>% 
  ggplot(aes(x = rate_increase, y = power, color = block)) +
  geom_point() + geom_line() +
  facet_wrap(~ rho)
```

Expected:

```{r}
block_5_4k %>% 
  inner_join(hotspots_4k, by = c('start', 'end')) %>% 
  # filter(rate_ratio >= rate_increase) %>% # uncomment for no. detected hotspots
  group_by(rho, rate_increase) %>% 
  tally()

block_5_6k %>% 
  inner_join(hotspots_6k, by = c('start', 'end')) %>% 
  # filter(rate_ratio >= rate_increase) %>% # uncomment for no. detected hotspots
  group_by(rho, rate_increase) %>% 
  tally()
```

Creating a generalized function to repeat the above operation for different window/flank sizes:

```{r}
hotspot_power <- function(window, flank, hot_length, hotspot_df, verbose = FALSE) {
  # read in files
  dfs_all <- list()
  blocks <- c(5, 10, 50, 100)
  for (i in seq_along(blocks)) {
    dfs_all[[i]] <- load_ldhelmet_files(window, flank, blocks[i], hot_length)
  }
  names(dfs_all) <- blocks
  
  # hotspot counts
  if (hot_length == 4) {
    max_hotspots <- 40
  } else if (hot_length == 6) {
    max_hotspots <- 60
  }
  dfs_all %<>%
    map_dfr(
      ~ inner_join(., hotspot_df, by = c('start', 'end')) %>% 
        filter(rate_ratio >= 5) %>% 
        group_by(rho, rate_increase) %>% 
        tally() %>% 
        mutate(power = n / max_hotspots),
      .id = 'block'
    )
  if (verbose == TRUE) {
    message('done')
  }
  return(dfs_all)
}

```


Trying out flank = [20, 60, 80, 100]:

```{r}
options(scipen = 50) # prevent 100000 from being converted to 1e05

flank_20k_4 <- hotspot_power(2000, 20000, 4, hotspots_4k)
flank_40k_4 <- hotspot_power(2000, 40000, 4, hotspots_4k)
flank_60k_4 <- hotspot_power(2000, 60000, 4, hotspots_4k)
flank_80k_4 <- hotspot_power(2000, 80000, 4, hotspots_4k)
flank_100k_4 <- hotspot_power(2000, 100000, 4, hotspots_4k)
flank_20k_6 <- hotspot_power(2000, 20000, 6, hotspots_6k)
flank_40k_6 <- hotspot_power(2000, 40000, 6, hotspots_6k)
flank_60k_6 <- hotspot_power(2000, 60000, 6, hotspots_6k)
flank_80k_6 <- hotspot_power(2000, 80000, 6, hotspots_6k)
flank_100k_6 <- hotspot_power(2000, 100000, 6, hotspots_6k)
```

Plots:

```{r}
power_plot <- function(d) {
  p <- d %>% 
    ggplot(aes(x = rate_increase, y = power, color = block)) +
    geom_point() + 
    geom_line() +
    facet_wrap(~ rho) +
    coord_cartesian(y = c(0, 1))
  return(p)
}
```

```{r}
power_plot(flank_20k_4)
power_plot(flank_40k_4)
power_plot(flank_60k_4)
power_plot(flank_80k_4)
power_plot(flank_100k_4)
```

```{r}
flank_list_4 <- list(flank_20k_4, flank_40k_4, flank_60k_4, flank_80k_4, flank_100k_4)
flank_list_6 <- list(flank_20k_6, flank_40k_6, flank_60k_6, flank_80k_6, flank_100k_6)
names(flank_list_4) <- c(20, 40, 60, 80, 100)
names(flank_list_6) <- c(20, 40, 60, 80, 100)

flank_list_4 %>% 
  bind_rows(.id = 'flank') %>% 
  ggplot(aes(x = factor(flank, levels = c(20, 40, 60, 80, 100)), y = power)) +
  geom_boxplot() +
  facet_wrap(~ factor(block, levels = c(5, 10, 50, 100))) +
  coord_cartesian(y = c(0, 1)) +
  labs(x = 'flank')
```

```{r}
# power across all hotspots
flank_list_4 %>% 
  bind_rows(.id = 'flank') %>% 
  ungroup() %>% 
  filter(rho == 0.001) %>% 
  group_by(flank, block) %>% 
  summarise(power = sum(n) / 160) %>% 
  arrange(-power)

flank_list_6 %>% 
  bind_rows(.id = 'flank') %>% 
  ungroup() %>% 
  filter(rho == 0.001) %>% 
  group_by(flank, block) %>% 
  summarise(power = sum(n) / 240) %>% 
  arrange(-power)

power_total <- function(d, hotspot_size) {
  max_hotspots <- hotspot_size * 40
  out <- d %>% 
    bind_rows(.id = 'flank') %>% 
    ungroup() %>% 
    filter(rho == 0.001) %>% 
    group_by(flank, block) %>% 
    summarise(power = sum(n) / max_hotspots) %>% 
    arrange(-power) %>% 
    mutate(hotspot_size = hotspot_size)
  return(out)
}

# using flank_list from other Rmd
flank_list_final <- bind_rows(
  power_total(flank_list, 2),
  power_total(flank_list_4, 4),
  power_total(flank_list_6, 6)
) %>% 
  arrange(-power)

flank_list_final %>% 
  ungroup() %>% 
  group_by(hotspot_size) %>% 
  filter(power == max(power)) # only block 100 flank 100 marginally better than block 50 

flank_list_final %>% 
  ungroup() %>% 
  group_by(flank, block) %>% 
  summarise(mean_power = mean(power)) %>% 
  arrange(-mean_power)

```

with longer hotspots, data suggest it's better to go with a larger flank (100 kb) but differences in power
between what was used (60 kb, block = 5) are low

### Fig. S2 - Power to detect hotspots

```{r}
fig_s2 <- bind_rows(
  flank_list %>% bind_rows(.id = 'flank') %>% mutate(hotspot_size = '2000'),
  flank_list_4 %>% bind_rows(.id = 'flank') %>% mutate(hotspot_size = '4000'),
  flank_list_6 %>% bind_rows(.id = 'flank') %>% mutate(hotspot_size = '6000')
) %>% 
  filter(rho == 0.001) %>% 
  mutate(block = paste('block =', block)) %>% 
  ggplot(aes(x = factor(flank, levels = c(20, 40, 60, 80, 100)), y = power)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter() +
  facet_grid(
    hotspot_size ~ factor(block, 
    levels = c('block = 5', 'block = 10', 'block = 50', 'block = 100'))) +
  coord_cartesian(y = c(0, 1)) +
  labs(
    x = 'Flank size (kb)',
    y = 'Power to detect hotspots'
  ) +
  theme_bw() +
  theme(
    axis.title = element_text(family = 'Helvetica', size = 12),
    axis.text = element_text(family = 'Helvetica', size = 12, color = 'black'),
    panel.background = element_blank(),
    panel.grid = element_blank(),
    strip.background = element_blank(),
    strip.text = element_text(family = 'Helvetica', size = 12, color = 'black')
  )

fig_s2

ggsave(here('plots/fig_s2.pdf'), plot = fig_s2, width = din1, height = din2 * 1.25)
```

































